# Pythonéšèº«å¬-2020-10-09-æŠ€æœ¯ç²¾é€‰

> è‡´è¯»è€…ï¼šäº²çˆ±çš„ã€ŒPythonéšèº«å¬ã€çš„è§‚ä¼—ä»¬ï¼Œè¿™æ˜¯ç”±DE8UGçš„äººå·¥éæ™ºèƒ½ç»™ä½ å¸¦æ¥çš„æ–°çš„ä¸€æœŸæŠ€æœ¯ç²¾é€‰ã€‚  
> ä¸»è¦ä¸ºç¼–ç¨‹åˆå­¦è€…ï¼Œå¼€å‘å·¥ç¨‹å¸ˆï¼Œç®—æ³•å·¥ç¨‹å¸ˆï¼Œæ•°æ®åˆ†æå¸ˆï¼Œè¿ç»´ï¼Œæµ‹è¯•ï¼Œè¿è¥ï¼Œäº§å“ç­‰å„ä¸ªå²—ä½çš„Pythonçˆ±å¥½è€…å¸¦æ¥Pythonä¸–ç•Œçš„æµè¡Œè¶‹åŠ¿ï¼Œå‰æ²¿æŠ€æœ¯ã€‚  
> ä½ å¯ä»¥æŒ‘é€‰è‡ªå·±å–œæ¬¢çš„é¡¹ç›®å°½æƒ…ç©è€ï¼Œä»»ä½•æƒ³æ³•æ¬¢è¿ç•™è¨€è®¨è®ºã€‚  
> æœ¬æ–‡çš„ç»“æ„å’Œå†…å®¹ä¼šç»å¸¸æ›´æ–°ï¼Œæ¯å¤©10ï¼š24åˆ†å·¦å³å‘å¸ƒï¼Œæ„Ÿè°¢è®¢é˜…ğŸ†™å’Œæ”¶è—â˜†ã€‚  
>ï¼ˆç‚¹å‡»åŸæ–‡æˆ–åˆ°pythonradio.onlineç½‘ç«™æŸ¥çœ‹å¯ç‚¹å‡»çš„æ–‡æ¡£é“¾æ¥ï¼‰  

![](https://img2020.cnblogs.com/blog/152871/202010/152871-20201005104055252-1408177983.png)



## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /TheAlgorithms/Python
ğŸ‘‰All Algorithms implemented in Python  

ğŸ˜TOPICS: `python,algorithm,algorithms-implemented,algorithm-competitions,algos,sorts,searches,sorting-algorithms,education,learn,practice,community-driven,interview,hacktoberfest`  

â­ï¸STARSï¼š88537, ä»Šæ—¥ä¸Šå‡æ•°â†‘:406  

ğŸ‘‰READMEï¼š

## The Algorithms - Python

#### All algorithms implemented in Python (for education)

These implementations are for learning purposes. They may be less efficient than the implementations in the Python standard library.

### Contribution G...

åœ°å€ï¼š[https://github.com/TheAlgorithms/Python](https://github.com/TheAlgorithms/Python)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /eriklindernoren/ML-From-Scratch
ğŸ‘‰Machine Learning From Scratch. Bare bones NumPy implementations of machine learning models and algorithms with a focus on accessibility. Aims to cover everything from linear regression to deep learning.  

ğŸ˜TOPICS: `machine-learning,deep-learning,deep-reinforcement-learning,machine-learning-from-scratch,data-science,data-mining,genetic-algorithm`  

â­ï¸STARSï¼š17735, ä»Šæ—¥ä¸Šå‡æ•°â†‘:313  

ğŸ‘‰READMEï¼š

## Machine Learning From Scratch

### About
Python implementations of some of the fundamental Machine Learning models and algorithms from scratch.

The purpose of this project is not to produce as optimized and computationally efficient algorithms as possible
but rather to present the inner workings of them in a transparent and accessible way.

### Table of Contents
- [Machine Learning From Scratch](#machine-learning-from-scratch)
  * [About](#about)
  * [Table of Contents](#table-of-contents)
  * [Installation](#installation)
  * [Examples](#examples)
    + [Polynomial Regression](#polynomial-regression)
    + [Classification With CNN](#classification-with-cnn)
    + [Density-Based Clustering](#density-based-clustering)
    + [Generating Handwritten Digits](#generating-handwritten-digits)
    + [Deep Reinforcement Learning](#deep-reinforcement-learning)
    + [Image Reconstruction With RBM](#image-reconstruction-with-rbm)
    + [Evolutionary Evolved Neural Network](#evolutionary-evolved-neural-network)
    +...

åœ°å€ï¼š[https://github.com/eriklindernoren/ML-From-Scratch](https://github.com/eriklindernoren/ML-From-Scratch)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /nvbn/thefuck
ğŸ‘‰Magnificent app which corrects your previous console command.  

ğŸ˜TOPICS: `python,shell`  

â­ï¸STARSï¼š56332, ä»Šæ—¥ä¸Šå‡æ•°â†‘:172  

ğŸ‘‰READMEï¼š


*The Fuck* is a magnificent app, inspired by a [@liamosaur](https://twitter.com/liamosaur/)
[tweet](https://twitter.com/liamosaur/status/506975850596536320),
that corrects errors in previous console commands.


Is *The Fuck* too slow? [Try the experimental instant mode!](#experimental-instant-mode)


More examples:

âœ apt-get install vim
E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)
E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?

âœ fuck
sudo apt-get install vim [enter/â†‘/â†“/ctrl+c]
[sudo] password for nvbn:
Reading package lists... Done
...

âœ git push
fatal: The current branch master has no upstream branch.
To push the current branch and set the remote as upstream, use

    git push --set-upstream origin master


âœ fuck
git push --set-upstream origin master [enter/â†‘/â†“/ctrl+c]
Counting objects: 9, done.
...

âœ puthon
No command 'puthon' found, did you mean:
 Command 'python' from package 'python-minimal' (main)
 Command 'python' from package 'pyth...

åœ°å€ï¼š[https://github.com/nvbn/thefuck](https://github.com/nvbn/thefuck)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /Asabeneh/30-Days-Of-Python
ğŸ‘‰30 days of Python programming challenge is a step by step guide to learn Python programming language in 30 days.  

ğŸ˜TOPICS: `30-days-of-python,python`  

â­ï¸STARSï¼š1801, ä»Šæ—¥ä¸Šå‡æ•°â†‘:154  

ğŸ‘‰READMEï¼š

## ğŸ 30 Days Of Python 



|   # Day   | Topics                                                    |
|-----------|:-------------------------------------------------------------------------------------------------------------: |
|  01   |  [Introduction](./readme.md)      |
|  02   |  [Variables, Built-in Functions](./02_Day_Variables_builtin_functions/02_variables_builtin_functions.md)  |
|  03   |  [Operators](./03_Day_Operators/03_operators.md)    |
|  04   |  [Strings](./04_Day_Strings/04_strings.md)|
|  05   |  [Lists](./05_Day_Lists/05_lists.md)  |
|  06   |  [Tuples](./06_Day_Tuples/06_tuples.md) |
|  07   |  [Sets](./07_Day_Sets/07_sets.md)  |
|  08   |  [Dictionaries](./08_Day_Dictionaries/08_dictionaries.md)     |
|  09   |  [Conditionals](./09_Day_Conditionals/09_conditionals.md)     |
|  10   |  [Loops](./10_Day_Loops/10_loops.md)   |
|  11   |  [Functions](./11_Day_Functions/11_functions.md)     |
|  12   |  [Modules](./12_Day_Modules/12_modules.md)   |
|  13   |  [List Comprehension](../13_Day_Li...

åœ°å€ï¼š[https://github.com/Asabeneh/30-Days-Of-Python](https://github.com/Asabeneh/30-Days-Of-Python)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /AlfredoSequeida/fvid
ğŸ‘‰fvid is a project that aims to encode any file as a video using 1-bit color images to survive compression algorithms for data retrieval.  

ğŸ˜TOPICS: `open-source,ffmpeg,pillow,video,youtube,hacktoberfest2020,hacktoberfest`  

â­ï¸STARSï¼š156, ä»Šæ—¥ä¸Šå‡æ•°â†‘:50  

ğŸ‘‰READMEï¼š


[Demonstration/Explanation Video](https://youtu.be/yu_ZIr0q5rU)

fvid is a project that aims to encode any file as a video using 1-bit color images
to survive compression algorithms for data retrieval.

<p align="center">
    <img src="https://i.imgur.com/LVthky0.png" alt="fvid">
    </br>
</p>


## Installation

Requires installation of [FFmpeg](https://ffmpeg.org/download.html) and libmagic first, then install using pip3 

Linux/macOS

pip3 install fvid 

Windows 

py -m pip install fvid 

## Usage

Encoding files as videos
 
Linux/OSX

fvid -i [input file] -e

Windows 

py -m fvid -i [input file] -e

Retrieving data from videos
 
Linux/OSX

fvid -i [input video...

åœ°å€ï¼š[https://github.com/AlfredoSequeida/fvid](https://github.com/AlfredoSequeida/fvid)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /MaartenGr/BERTopic
ğŸ‘‰Leveraging BERT and a class-based TF-IDF to create easily interpretable topics.   

ğŸ˜TOPICS: `bert,transformers,topic-modeling,sentence-embeddings,nlp,machine-learning`  

â­ï¸STARSï¼š168, ä»Šæ—¥ä¸Šå‡æ•°â†‘:68  

ğŸ‘‰READMEï¼š

<img src="https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png" height="220" />


BERTopic is a topic modeling technique that leverages BERT embeddings and c-TF-IDF to create dense clusters
allowing for easily interpretable topics whilst keeping important words in the topic descriptions. 

Corresponding medium post can be found [here](https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6?source=friends_link&sk=0b5a470c006d1842ad4c8a3057063a99).

<a name="toc"/></a>
### Table of Contents  
<!--ts-->
   1. [About the Project](#about)  
   2. [Algorithm](#algorithm)  
        2.1. [Sentence Transformer](#sentence)  
        2.2. [UMAP + HDBSCAN](#umap)  
        2.3. [c-TF-IDF](#ctfidf)  
   3. [Getting Started](#gettingstarted)    
        3.1. [Installation](#installation)    
        3.2. [Basic Usage](#usage)   
        3.3. [Overview](#overview)    
   4. [Google Colaboratory](#colab)   
<!--te-->
 
<a name="about"/></a>
### 1. About the Project
[Back to ToC](#toc)  

T...

åœ°å€ï¼š[https://github.com/MaartenGr/BERTopic](https://github.com/MaartenGr/BERTopic)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /tensorflow/models
ğŸ‘‰Models and examples built with TensorFlow  

ğŸ˜TOPICS: ``  

â­ï¸STARSï¼š66557, ä»Šæ—¥ä¸Šå‡æ•°â†‘:25  

ğŸ‘‰READMEï¼š


## Welcome to the Model Garden for TensorFlow

The TensorFlow Model Garden is a repository with a number of different implementations of state-of-the-art (SOTA) models and modeling solutions for TensorFlow users. We aim to demonstrate the best practices for modeling so that TensorFlow users
can take full advantage of TensorFlow for their research and product development.

| Directory | Description |
|-----------|-------------|
| [official](official) | â€¢ A collection of example implementations for SOTA models using the latest TensorFlow 2's high-level APIs<br />â€¢ Officially maintained, supported, and kept up to date with the latest TensorFlow 2 APIs by TensorFlow<br />â€¢ Reasonably optimized for fast performance while still being easy to read |
| [research](research) | â€¢ A collection of research model implementations in TensorFlow 1 or 2 by researchers<br />â€¢ Maintained and supported by researchers |
| [community](community) | â€¢ A curated list of the GitHub repositories with machine learning models and impleme...

åœ°å€ï¼š[https://github.com/tensorflow/models](https://github.com/tensorflow/models)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /NVIDIA/NeMo
ğŸ‘‰NeMo: a toolkit for conversational AI  

ğŸ˜TOPICS: `deep-learning,speech-recognition,nlp,nlp-machine-learning,neural-network`  

â­ï¸STARSï¼š1985, ä»Šæ—¥ä¸Šå‡æ•°â†‘:13  

ğŸ‘‰READMEï¼š

 
|status| |license| |lgtm_grade| |lgtm_alerts| |black|

.. |status| image:: http://www.repostatus.org/badges/latest/active.svg
  :target: http://www.repostatus.org/#active
  :alt: Project Status: Active â€“ The project has reached a stable, usable state and is being actively developed.


.. |license| image:: https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg
  :target: https://github.com/NVIDIA/NeMo/blob/master/LICENSE
  :alt: NeMo core license and license for collections in this repo

.. |lgtm_grade| image:: https://img.shields.io/lgtm/grade/python/g/NVIDIA/NeMo.svg?logo=lgtm&logoWidth=18
  :target: https://lgtm.com/projects/g/NVIDIA/NeMo/context:python
  :alt: Language grade: Python

.. |lgtm_alerts| image:: https://img.shields.io/lgtm/alerts/g/NVIDIA/NeMo.svg?logo=lgtm&logoWidth=18
  :target: https://lgtm.com/projects/g/NVIDIA/NeMo/alerts/
  :alt: Total alerts

.. |black| image:: https://img.shields.io/badge/code%20style-black-000000.svg
  :target: https://github.com/psf/black
  :alt: Code st...

åœ°å€ï¼š[https://github.com/NVIDIA/NeMo](https://github.com/NVIDIA/NeMo)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /marblexu/PythonPlantsVsZombies
ğŸ‘‰a simple PlantsVsZombies game  

ğŸ˜TOPICS: ``  

â­ï¸STARSï¼š1534, ä»Šæ—¥ä¸Šå‡æ•°â†‘:26  

ğŸ‘‰READMEï¼š

## PythonPlantsVsZombies
  A simple PlantsVsZombies game. <br>
  `It's only for personal learning and noncommercial use. If this game infringes the copyright, please let me know.`
* implement plants: sunflower, peashooter, wallnut, snowpeashooter, cherrybomb, threepeashooter, chomper, puffshroom, potatomine, spikeweed, scaredyshroom, squash, scaredyshroom, jalapeno, sunShroom, iceShroom, hypnoShroom.
* implement zombies: zombie, flagzombie, coneheadzombie, bucketheadzombie, newspaperzombie.
* use json file to store level data (e.g.position and time of zombies, background info)
* support to select plant cards at the beginning of the level
* support day level,...

åœ°å€ï¼š[https://github.com/marblexu/PythonPlantsVsZombies](https://github.com/marblexu/PythonPlantsVsZombies)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /malwaredllc/byob
ğŸ‘‰An open-source post-exploitation framework for students, researchers and developers.  

ğŸ˜TOPICS: `encrypted-connections,platform-independent,zero-configuration,no-dependencies,reverse-shells,antiforensics,post-exploitation`  

â­ï¸STARSï¼š5223, ä»Šæ—¥ä¸Šå‡æ•°â†‘:28  

ğŸ‘‰READMEï¼š

<img src="https://raw.githubusercontent.com/malwaredllc/byob/master/byob/static/byob_logo_email-black.png" width="400px"></img>


Questions? [Join our Discord server](https://discord.gg/8FsSrw7)

__Disclaimer__: This project should be used for authorized testing or educational purposes only.

BYOB is an open-source post-exploitation framework for students, researchers and developers. It includes features such as:
- Pre-built C2 server
- Custom payload generator
- 12 post-exploitation modules

It is designed to allow students and developers to easily implement their own code and add cool new
features *without* having to write a C2 server or Remote Administration Tool from scratch.

This project has 2 main parts: the **original console-based application** (`/byob`) and the **web GUI** (`/web-gui`).

## Web GUI

### Dashboard
A control panel for your C2 server with a point-and-click interface for executing post-exploitation modules. The control panel includes an interactive map of client machines and a dashboard...

åœ°å€ï¼š[https://github.com/malwaredllc/byob](https://github.com/malwaredllc/byob)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /Pitt-CSC/Summer2021-Internships
ğŸ‘‰Collection of Summer 2021 tech internships!  

ğŸ˜TOPICS: `interview-preparation,internships,hacktoberfest`  

â­ï¸STARSï¼š2131, ä»Šæ—¥ä¸Šå‡æ•°â†‘:13  

ğŸ‘‰READMEï¼š

## Summer 2021 Internships â˜€ï¸ğŸ‘©â€ğŸ’»
Use this repo to share and keep track of any tech-related internships. For a [Google Sheet ğŸ“ version of this repo (that remains in sync with this table) click here](https://docs.google.com/spreadsheets/d/1bJq7YQV19TWyzPCBeQi5P4uOm8uiAAm2AHCnVNGRIDg/edit#gid=0)! For more tips on the internship process check out the [Zero to Offer ğŸ“ˆ program here](https://www.pittcs.wiki/zero-to-offer).


ğŸ“«  Want weekly internship postings in your inbox? Join the internship newsletter [here](https://forms.gle/khRdKEm9AXaFAZg97)!

ğŸ“â€ƒCheck out our New Grad repo [here](https://github.com/Pitt-CSC/NewGrad-2021).

ğŸ¤—â€ƒ**Contribute by submitting a [pull request](https://github.com/susam/gitpr#create-pull-request) or [filling out this form](https://bit.ly/3d5O76c)!**  ğŸ¤—

### The List ğŸ‘”

| Name  |  Location |  Notes |
|---|---|-------------|
|[Akuna Capital](https://akunacapital.com/careers?&experience=intern&department=&location=&search_term=#careers)| Boston, Chicago, International Locations | |
|[Apple]...

åœ°å€ï¼š[https://github.com/Pitt-CSC/Summer2021-Internships](https://github.com/Pitt-CSC/Summer2021-Internships)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /timoschick/pet
ğŸ‘‰This repository contains the code for "Exploiting Cloze Questions for Few-Shot Text Classification and Natural Language Inference"  

ğŸ˜TOPICS: `nlp,python,machine-learning`  

â­ï¸STARSï¼š475, ä»Šæ—¥ä¸Šå‡æ•°â†‘:33  

ğŸ‘‰READMEï¼š

## Pattern-Exploiting Training (PET)

This repository contains the code for [Exploiting Cloze Questions for Few-Shot Text Classification and Natural Language Inference](https://arxiv.org/abs/2001.07676) and [It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners](https://arxiv.org/abs/2009.07118). The papers introduce pattern-exploiting training (PET), a semi-supervised training procedure that reformulates input examples as cloze-style phrases. In low-resource settings, PET and iPET significantly outperform regular supervised training, various semi-supervised baselines and even GPT-3 despite requiring 99.9% less parameters. The iterative variant of PET (iPET) trains multiple generations of models and can even be used without any training data.

<table>
    <tr>
        <th>#Examples</th>
        <th>Training Mode</th>
        <th>Yelp (Full)</th>
        <th>AG's News</th>
        <th>Yahoo Questions</th>
        <th>MNLI</th>
    </tr>
    <tr>
        <td rowspan="2" align="center...

åœ°å€ï¼š[https://github.com/timoschick/pet](https://github.com/timoschick/pet)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /keras-team/keras
ğŸ‘‰Deep Learning for humans  

ğŸ˜TOPICS: `deep-learning,tensorflow,neural-networks,machine-learning,data-science,python`  

â­ï¸STARSï¼š49932, ä»Šæ—¥ä¸Šå‡æ•°â†‘:16  

ğŸ‘‰READMEï¼š

ï»¿# Keras: Deep Learning for humans




Keras is a deep learning API written in Python, running on top of the machine learning platform TensorFlow.

Read the documentation at [Keras.io](https://keras.io).



### Multi-backend Keras and tf.keras

**Multi-backend Keras has been discontinued. At this time, we recommend that Keras us...

åœ°å€ï¼š[https://github.com/keras-team/keras](https://github.com/keras-team/keras)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /public-apis/public-apis
ğŸ‘‰A collective list of free APIs for use in software and web development.  

ğŸ˜TOPICS: ``  

â­ï¸STARSï¼š97638, ä»Šæ—¥ä¸Šå‡æ•°â†‘:61  

ğŸ‘‰READMEï¼š


A collective list of free APIs for use in software and web development.

A public API for this project can be found [here](https://github.com/davemachado/public-api)!

For information on contributing to this project, please see the [contributing guide](.github/CONTRIBUTING.md).

Please note a passing build status indicates all listed APIs are available since the last update. A failing build status indicates that 1 or more services may be unavailable at the moment.

### Index

* [Animals](#animals)
* [Anime](#anime)
* [Anti-Malware](#anti-malware)
* [Art & Design](#art--design)
* [Books](#books)
* [Business](#business)
* [Calendar](#calendar)
* [Cloud Storage & File Sharing](#cloud-storage--file-sharing)
* [Continuous Integration](#continuous-integration)
* [Cryptocurrency](#cryptocurrency)
* [Currency Exchange](#currency-exchange)
* [Data Validation](#data-validation)
* [Development](#development)
* [Dictionaries](#dictionaries)
* [Documents & Productivity](#documents--productivity)
* [Environment](#environm...

åœ°å€ï¼š[https://github.com/public-apis/public-apis](https://github.com/public-apis/public-apis)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /hamuchiwa/AutoRCCar
ğŸ‘‰OpenCV Python Neural Network Autonomous RC Car  

ğŸ˜TOPICS: ``  

â­ï¸STARSï¼š2782, ä»Šæ—¥ä¸Šå‡æ•°â†‘:18  

ğŸ‘‰READMEï¼š

### AutoRCCar
#### Python3 + OpenCV3

See self-driving in action  

<a href="http://www.youtube.com/watch?feature=player_embedded&v=BBwEF6WBUQs
" target="_blank"><img src="http://img.youtube.com/vi/BBwEF6WBUQs/0.jpg" width="360" height="240" border="10" /></a>

This project builds a self-driving RC car using Raspberry Pi, Arduino and open source software. Raspberry Pi collects inputs from a camera module and an ultrasonic sensor, and sends data to a computer wirelessly. The computer processes input images and sensor data for object detection (stop sign and traffic light) and collision avoidance respectively. A neural network model runs on computer and makes predictions for steering based on input images. Predictions are then sent to the Arduino for RC car control. 
  
#### Setting up environment with Anaconda
  1. Install [`miniconda(Python3)`](https://conda.io/miniconda.html) on your computer
  2. Create `auto-rccar` environment with all necessary libraries for this project  
     ```conda env create -f envi...

åœ°å€ï¼š[https://github.com/hamuchiwa/AutoRCCar](https://github.com/hamuchiwa/AutoRCCar)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /facebookresearch/frankmocap
ğŸ‘‰A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator  

ğŸ˜TOPICS: ``  

â­ï¸STARSï¼š519, ä»Šæ—¥ä¸Šå‡æ•°â†‘:17  

ğŸ‘‰READMEï¼š

## FrankMocap: A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator

FrankMocap pursues an easy-to-use single view 3D motion capture system developed by Facebook AI Research (FAIR). FrankMocap provides state-of-the-art 3D pose estimation outputs for body, hand, and body+hands in a single system. The core objective of FrankMocap is to democratize the 3D human pose estimation technology, enabling anyone (researchers, engineers, developers, artists, and others) can easily obtain 3D motion capture outputs from videos and images.

### Key Features
- Body Motion Capture:
<p>
    <img src="https://github.com/jhugestar/jhugestar.github.io/blob/master/img/eft_bodymocap.gif" height="200">
</p>

- Hand Motion Capture
<p>
    <img src="https://github.com/jhugestar/jhugestar.github.io/blob/master/img/frankmocap_hand.gif" height="200">
</p>

- Egocentric Hand Motion Capture
<p>
    <img src="https://github.com/jhugestar/jhugestar.github.io/blob/master/img/frankmotion_egohand.gif" height="150">
</p>

- Whole bod...

åœ°å€ï¼š[https://github.com/facebookresearch/frankmocap](https://github.com/facebookresearch/frankmocap)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /ageitgey/face_recognition
ğŸ‘‰The world's simplest facial recognition api for Python and the command line  

ğŸ˜TOPICS: `machine-learning,face-detection,face-recognition,python`  

â­ï¸STARSï¼š36556, ä»Šæ—¥ä¸Šå‡æ•°â†‘:23  

ğŸ‘‰READMEï¼š

## Face Recognition

_You can also read a translated version of this file [in Chinese ç®€ä½“ä¸­æ–‡ç‰ˆ](https://github.com/ageitgey/face_recognition/blob/master/README_Simplified_Chinese.md) or [in Korean í•œêµ­ì–´](https://github.com/ageitgey/face_recognition/blob/master/README_Korean.md) or [in Japanese æ—¥æœ¬èª](https://github.com/m-i-k-i/face_recognition/blob/master/README_Japanese.md)._

Recognize and manipulate faces from Python or from the command line with
the world's simplest face recognition library.

Built using [dlib](http://dlib.net/)'s state-of-the-art face recognition
built with deep learning. The model has an accuracy of 99.38% on the
[Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/) benchmark.

This also provides a simple `face_recognition` command line tool that lets
you do face recognition on a folder of images from the command line!



### Features

##### Find faces in pictures

Find all the faces that appear in a picture:


import face_recognition
image = face_recognition.load_image_file("your_file...

åœ°å€ï¼š[https://github.com/ageitgey/face_recognition](https://github.com/ageitgey/face_recognition)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /rusty1s/pytorch_geometric
ğŸ‘‰Geometric Deep Learning Extension Library for PyTorch  

ğŸ˜TOPICS: `pytorch,geometric-deep-learning,graph-neural-networks`  

â­ï¸STARSï¼š9081, ä»Šæ—¥ä¸Šå‡æ•°â†‘:13  

ğŸ‘‰READMEï¼š

[pypi-image]: https://badge.fury.io/py/torch-geometric.svg
[pypi-url]: https://pypi.python.org/pypi/torch-geometric
[build-image]: https://travis-ci.org/rusty1s/pytorch_geometric.svg?branch=master
[build-url]: https://travis-ci.org/rusty1s/pytorch_geometric
[docs-image]: https://readthedocs.org/projects/pytorch-geometric/badge/?version=latest
[docs-url]: https://pytorch-geometric.readthedocs.io/en/latest/?badge=latest
[coverage-image]: https://codecov.io/gh/rusty1s/pytorch_geometric/branch/master/graph/badge.svg
[coverage-url]: https://codecov.io/github/rusty1s/pytorch_geometric?branch=master
[contributing-image]: https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat
[contributing-url]: https://github.com/rusty1s/pytorch_geometric/blob/master/CONTRIBUTING.md
[slack-image]: https://img.shields.io/badge/slack-pyg-brightgreen
[slack-url]: https://torchgeometricco.slack.com/join/shared_invite/zt-hn9vter8-EQn4L4wLfE7PZEYbLMlw~Q#/

<p align="center">
  <img width="40%" src="https://raw.githu...

åœ°å€ï¼š[https://github.com/rusty1s/pytorch_geometric](https://github.com/rusty1s/pytorch_geometric)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /scikit-learn/scikit-learn
ğŸ‘‰scikit-learn: machine learning in Python  

ğŸ˜TOPICS: `machine-learning,python,statistics,data-science,data-analysis`  

â­ï¸STARSï¼š42531, ä»Šæ—¥ä¸Šå‡æ•°â†‘:14  

ğŸ‘‰READMEï¼š

.. -*- mode: rst -*-

|Azure|_ |Travis|_ |Codecov|_ |CircleCI|_ |PythonVersion|_ |PyPi|_ |DOI|_

.. |Azure| image:: https://dev.azure.com/scikit-learn/scikit-learn/_apis/build/status/scikit-learn.scikit-learn?branchName=master
.. _Azure: https://dev.azure.com/scikit-learn/scikit-learn/_build/latest?definitionId=1&branchName=master

.. |Travis| image:: https://api.travis-ci.org/scikit-learn/scikit-learn.svg?branch=master
.. _Travis: https://travis-ci.org/scikit-learn/scikit-learn

.. |Codecov| image:: https://codecov.io/github/scikit-learn/scikit-learn/badge.svg?branch=master&service=github
.. _Codecov: https://codecov.io/github/scikit-learn/scikit-learn?branch=master

.. |CircleCI| image:: https://circleci.com/gh/scikit-learn/scikit-learn/tree/master.svg?style=shield&circle-token=:circle-token
.. _CircleCI: https://circleci.com/gh/scikit-learn/scikit-learn

.. |PythonVersion| image:: https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-blue
.. _PythonVersion: https://img.shields.io/badge/python-3.6...

åœ°å€ï¼š[https://github.com/scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /facebookresearch/ParlAI
ğŸ‘‰A framework for training and evaluating AI models on a variety of openly available dialogue datasets.  

ğŸ˜TOPICS: ``  

â­ï¸STARSï¼š6663, ä»Šæ—¥ä¸Šå‡æ•°â†‘:11  

ğŸ‘‰READMEï¼š

<p align="center">
 <img width="70%" src="docs/source/\my_static/img/parlai.png" />
</p>

<p align="center">
   <a href="https://github.com/facebookresearch/ParlAI/blob/master/LICENSE">
    <img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="CircleCI" />
  </a>
   <a href="https://pypi.org/project/parlai/">
    <img src="https://img.shields.io/pypi/v/parlai?color=blue&label=release" alt="CircleCI" />
  </a>
    <a href="https://circleci.com/gh/facebookresearch/ParlAI/tree/master">
    <img src="https://img.shields.io/circleci/build/github/facebookresearch/ParlAI/master" alt="Coverage" />
  </a>
    <a href="https://codecov.io/gh/facebookresearch/ParlAI">
    <img src="https://img.shields.io/codecov/c/github/facebookresearch/ParlAI" alt="GitHub contributors" />
  </a>
    <a href="https://img.shields.io/github/contributors/facebookresearch/ParlAI">
    <img src="https://img.shields.io/github/contributors/facebookresearch/ParlAI"/>
  </a>
    <a href="https://twitter.com/parlai_parley">
    <img src...

åœ°å€ï¼š[https://github.com/facebookresearch/ParlAI](https://github.com/facebookresearch/ParlAI)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /eladrich/pixel2style2pixel
ğŸ‘‰Official Implementation for "Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation"  

ğŸ˜TOPICS: `image-translation,stylegan,generative-adversarial-network,stylegan-encoder`  

â­ï¸STARSï¼š185, ä»Šæ—¥ä¸Šå‡æ•°â†‘:67  

ğŸ‘‰READMEï¼š

## Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation
  <a href="https://arxiv.org/abs/2008.00951"><img src="https://img.shields.io/badge/arXiv-2008.00951-b31b1b.svg"></a>
  <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg"></a>

> We present a generic image-to-image translation framework, Pixel2Style2Pixel (pSp). Our pSp framework is based on a novel encoder network that directly generates a series of style vectors which are fed into a pretrained StyleGAN generator, forming the extended W+ latent space. We first show that our encoder can directly embed real images into W+, with no additional optimization. We further introduce a dedicated identity loss which is shown to achieve improved performance in the reconstruction of an input image. We demonstrate pSp to be a simple architecture that, by leveraging a well-trained, fixed generator network, can be easily applied on a wide-range of image-to-image translation tasks. Solving these t...

åœ°å€ï¼š[https://github.com/eladrich/pixel2style2pixel](https://github.com/eladrich/pixel2style2pixel)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /jantic/DeOldify
ğŸ‘‰A Deep Learning based project for colorizing and restoring old images (and video!)  

ğŸ˜TOPICS: ``  

â­ï¸STARSï¼š11699, ä»Šæ—¥ä¸Šå‡æ•°â†‘:12  

ğŸ‘‰READMEï¼š


## DeOldify

**Quick Start**: The easiest way to colorize images using DeOldify (for free!) is here: [DeOldify Image Colorization on DeepAI](https://deepai.org/machine-learning-model/colorizer)

The **most advanced** version of DeOldify image colorization is available here, exclusively.  Try a few images for free! [MyHeritiage In Color](https://www.myheritage.com/incolor)


Image (artistic) [<img src="https://colab.research.google.com/assets/colab-badge.svg" align="center">](https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb) |
Video [<img src="https://colab.research.google.com/assets/colab-badge.svg" align="center">](https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb)

**NEW** Having trouble with the default image colorizer, aka "artistic"?  Try the "stable" one below.  It generally won't produce colors that are as interesting as "artistic", but the glitches are noticeably reduced.  

Image (stable) [<img src="https://co...

åœ°å€ï¼š[https://github.com/jantic/DeOldify](https://github.com/jantic/DeOldify)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /NLP-LOVE/ML-NLP
ğŸ‘‰æ­¤é¡¹ç›®æ˜¯æœºå™¨å­¦ä¹ (Machine Learning)ã€æ·±åº¦å­¦ä¹ (Deep Learning)ã€NLPé¢è¯•ä¸­å¸¸è€ƒåˆ°çš„çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°ï¼Œä¹Ÿæ˜¯ä½œä¸ºä¸€ä¸ªç®—æ³•å·¥ç¨‹å¸ˆå¿…ä¼šçš„ç†è®ºåŸºç¡€çŸ¥è¯†ã€‚  

ğŸ˜TOPICS: `nlp,machine-learning,deep-learning`  

â­ï¸STARSï¼š6531, ä»Šæ—¥ä¸Šå‡æ•°â†‘:19  

ğŸ‘‰READMEï¼š

### é¡¹ç›®ä»‹ç»

- æ­¤é¡¹ç›®æ˜¯**æœºå™¨å­¦ä¹ ã€NLPé¢è¯•**ä¸­å¸¸è€ƒåˆ°çš„**çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°**ï¼Œä¹Ÿæ˜¯ä½œä¸ºä¸€ä¸ªç®—æ³•å·¥ç¨‹å¸ˆå¿…ä¼šçš„ç†è®ºåŸºç¡€çŸ¥è¯†ã€‚
- æ—¢ç„¶æ˜¯ä»¥é¢è¯•ä¸ºä¸»è¦ç›®çš„ï¼Œäº¦ä¸å¯ä»¥ç¯‡æ¦‚å…¨ï¼Œè¯·è°…è§£ï¼Œæœ‰é—®é¢˜å¯æå‡ºã€‚
- æ­¤é¡¹ç›®ä»¥å„ä¸ªæ¨¡å—ä¸ºåˆ‡å…¥ç‚¹ï¼Œè®©å¤§å®¶æœ‰ä¸€ä¸ªæ¸…æ™°çš„çŸ¥è¯†ä½“ç³»ã€‚
- æ­¤é¡¹ç›®äº¦å¯æ‹¿æ¥å¸¸è¯»ã€å¸¸è®°ä»¥åŠé¢è¯•æ—¶å¤ä¹ ä¹‹ç”¨ã€‚
- æ¯ä¸€ç« é‡Œçš„é—®é¢˜éƒ½æ˜¯é¢è¯•æ—¶æœ‰å¯èƒ½é—®åˆ°çš„çŸ¥è¯†ç‚¹ï¼Œå¦‚æœ‰é—æ¼å¯è”ç³»æˆ‘è¿›è¡Œè¡¥å……ï¼Œç»“å°¾å¤„éƒ½æœ‰ç®—æ³•çš„**å®æˆ˜ä»£ç æ¡ˆä¾‹**ã€‚
- æ€ç»´å¯¼å›¾ï¼Œ**è¯·å…³æ³¨ AIArea å…¬ä¼—å·å¹¶å›å¤ï¼šNLPæ€ç»´å¯¼å›¾** ï¼Œå³èƒ½ä¸‹è½½é«˜æ¸…å¤§å›¾ã€‚





### ç›®å½•

- **é¡¹ç›®æŒç»­æ›´æ–°ä¸­......**

| æ¨¡å—     | ç« èŠ‚                                                         | è´Ÿè´£äºº(GitHub)                          | è”ç³»QQ    |
| -------- | ------------------------------------------------------------ | --------------------------------------- | --------- |
| æœºå™¨å­¦ä¹  | [1. çº¿æ€§å›å½’(Liner Regression)](https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/Liner%20Regression/1.Liner%20Regression.md) | [@mantchs](https://github.com/NLP-LOVE) | 448966528 |
| æœºå™¨å­¦ä¹  | [2. é€»è¾‘å›å½’(Logistics Regression)](https://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/2.Logistics%20Regression/2.Logistics%20Regression.md) | [@mantchs](https://github.com/NLP-LOVE) | 448966528 |
| æœºå™¨å­¦ä¹  | [3. å†³ç­–æ ‘(Desision Tree)](https://github.com/NLP...

åœ°å€ï¼š[https://github.com/NLP-LOVE/ML-NLP](https://github.com/NLP-LOVE/ML-NLP)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /Atcold/pytorch-Deep-Learning
ğŸ‘‰Deep Learning (with PyTorch)  

ğŸ˜TOPICS: `jupyter-notebook,pytorch,deep-learning,neural-nets`  

â­ï¸STARSï¼š3012, ä»Šæ—¥ä¸Šå‡æ•°â†‘:116  

ğŸ‘‰READMEï¼š


This notebook repository now has a [companion website](https://atcold.github.io/pytorch-Deep-Learning/), where all the course material can be found in video and textual format.

<!-- English - Mandarin - Korean - Spanish - Italian - Turkish - Japanese - Arabic - French - Farsi - Russian -->
[ğŸ‡¬ğŸ‡§](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/README.md) &nbsp; [ğŸ‡¨ğŸ‡³](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/docs/zh/README-ZH.md) &nbsp; [ğŸ‡°ğŸ‡·](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/docs/ko/README-KO.md) &nbsp; [ğŸ‡ªğŸ‡¸](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/docs/es/README-ES.md) &nbsp; [ğŸ‡®ğŸ‡¹](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/docs/it/README-IT.md) &nbsp; [ğŸ‡¹ğŸ‡·](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/docs/tr/README-TR.md) &nbsp; [ğŸ‡¯ğŸ‡µ](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/docs/ja/README-JA.md) &nbsp; [ğŸ‡¸ğŸ‡¦](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/docs/ar/README-AR.m...

åœ°å€ï¼š[https://github.com/Atcold/pytorch-Deep-Learning](https://github.com/Atcold/pytorch-Deep-Learning)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /parrt/tensor-sensor
ğŸ‘‰The goal of this library is to generate more helpful exception messages for numpy/pytorch matrix algebra expressions.   

ğŸ˜TOPICS: `numpy,pytorch,matrix,vector,debugging,tracing`  

â­ï¸STARSï¼š188, ä»Šæ—¥ä¸Šå‡æ•°â†‘:31  

ğŸ‘‰READMEï¼š

## Tensor Sensor

<img src="https://explained.ai/tensor-sensor/images/teaser.png" width="50%" align="right">One of the biggest challenges when writing code to implement deep learning networks, particularly for us newbies, is getting all of the tensor (matrix and vector) dimensions to line up properly. It's really easy to lose track of tensor dimensionality in complicated expressions involving multiple tensors and tensor operations.  Even when just feeding data into predefined [Tensorflow](https://www.tensorflow.org/) network layers, we still need to get the dimensions right. When you ask for improper computations, you're going to run into some less than helpful exception messages.  To help myself and other programmers debug tensor code, I built this library.  TensorSensor clarifies exceptions by augmenting messages and visualizing Python code to indicate the shape of tensor variables (see figure to the right for a teaser). It works with [Tensorflow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/...

åœ°å€ï¼š[https://github.com/parrt/tensor-sensor](https://github.com/parrt/tensor-sensor)

---


## ğŸ¤©Pythonéšèº«å¬-æŠ€æœ¯ç²¾é€‰ï¼š /slundberg/shap
ğŸ‘‰A game theoretic approach to explain the output of any machine learning model.  

ğŸ˜TOPICS: `interpretability,machine-learning,deep-learning,gradient-boosting,shap,shapley,explainability`  

â­ï¸STARSï¼š10395, ä»Šæ—¥ä¸Šå‡æ•°â†‘:15  

ğŸ‘‰READMEï¼š



<p align="center">
  <img src="https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_header.png" width="800" />
</p>

<a href="https://travis-ci.org/slundberg/shap"><img src="https://travis-ci.org/slundberg/shap.svg?branch=master"></a>

**SHAP (SHapley Additive exPlanations)** is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see [papers](#citations) for details and citations).

<!--**SHAP (SHapley Additive exPlanations)** is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods [1-7] and representing the only possible consistent and locally accurate additive feature attribution method based on expectations (see our [papers](#citations) for details and citations).-->



### Install

Shap can be installed from either ...

åœ°å€ï¼š[https://github.com/slundberg/shap](https://github.com/slundberg/shap)

---
